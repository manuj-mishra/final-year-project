
Since the 1970s, John Conway's Game of Life, often shortened to just ``Life'', has garnered great academic interest as an example of emergent complexity. Life is a cellular automaton (CA), a discrete model of computation that simulates localised interactions of state-storing ``cells''. CA can model real-world dynamical systems such as fluid flow\cite{wolf2004lattice}, tumour growth\cite{reher2017cell}, and urban land use\cite{white2000high}. Automatically learning CA models from observations of such systems could save time and yield more accurate predictions. Deep learning has been shown to effectively learn CA parameters from artifically generated observations (\textit{full rule dynamics})\cite{wulff1992learning}. We investigate the use of evolutionary algorithms to this end.\\

We build a cellular automaton simulator and evolutionary algorithm toolkit to optimize life-like CA, a class of discrete state CA. As a precursory goal, we build a CA-based procedural maze generator which is optimized using the toolkit. We then learn the full rule dynamics of life-like CA. Ultimately, we extend the simulator and toolkit to Gray-Scott models\cite{gray1983autocatalytic}, a class of continuous state CA.\\

We extend existing work around procedural generation of mazes using CA\cite{adams2017procedural} through improved learning processes, fitness functions, and post-processing algorithms. We present, for the first time, evolutionary algorithms to learn the full rule dynamics of 2D cellular automata. For life-like CA, we show that genetic algorithms can learn global optima for 100\% of targets in a test set of 100 random samples while traversing, on average, less than 0.05\% of the search space. We develop a learning pipeline for continuous-state CA and find locally optimal regions to which genetic algorithms and self-adapting evolutionary strategies converge.