\chapter{Modelling Gray-Scott Systems} \label{gray-scott}

To learn Gray-Scott models, the evolutionary algorithm toolkit is extended with a new simulator, a modified genetic algorithm, and support for evolutionary strategies (ES). We explore each of these extensions in this chapter.

\section{Simulator} \label{sec:simulator-2}

In this setting, we run a discretized simulation of a continuous system so there are more subtleties to consider. We use two matrices of floats to store the density of $u$ and $v$ across the CA. To simulate the change in these densities efficiently, we use a pair of finite-difference equations that approximate the continuous partial differential equations defined in Def~\ref{def:reaction-diffusion}. We first define discrete approximations for the derivative of each density in Def~\ref{def:gs}.
\begin{definition}[Gray-Scott Model]\label{def:gs}
\begin{align}
  \dot{u} &= -uv^2 + f(1-u) + r_u \mathcal{D}(u)\\
  \dot{v} &= uv^2 - (f+k)v + r_v \mathcal{D}(v)
\end{align}
\end{definition}
Each equation has 3 terms. From left to right, these are the reaction term, the external term and the diffusion term. This is exactly the same as the continuous definition, Def~\ref{def:reaction-diffusion}, with the exception of the discrete Laplace operator $\mathcal{D}$ which replaces the continuous Laplacian $\Delta$. Calculating the first two terms is simple enough as we are given the feed and kill rates.  However, the third term must approximate the Laplacian which is usually computationally intensive to calculate. To do this, we use a kernel that, when convolved over the density matrices of $u$ and $v$, produces matrices whose entries are approximations of $\Delta u(x,y)$ and $\Delta v(x,y)$ respectively. Different kernels have been used for this convolution in the literature. One example used in Compeau's Biological Modelling book\cite{compeau} is
\begin{equation}
  K= \begin{bmatrix}
    0.05 & 0.2 & 0.05\\
    0.2 & -1 & 0.2\\
    0.05 & 0.2 & 0.05
  \end{bmatrix}
\end{equation}
Another popular choice is the nine-point stencil\cite{rosser1975nine}.
\begin{equation}
  \Delta^{(9)}_h = \begin{bmatrix}
    0.25 & 0.5 & 0.25\\
    0.5 & -3 & 0.5\\
    0.25 & 0.5 & 0.25
  \end{bmatrix}
\end{equation}
Testing on a few examples revealed that both kernels capture complex diffusion behaviour with similar effectiveness. However, the choice of kernel is not arbitrary and these two choices are well principled. We briefly outline the reasoning behind the nine-point stencil. If we consider $u$ as a function of only $x$ (i.e fix $y$ and $t$ constant) and rearrange the Taylor series expansions for $u(x+h)$ and $u(x-h)$, we get
\begin{align}
  \pdv{u}{x} &= \frac{u(x+h) - u(x)}{h} - \frac{u^{(2)}(x)}{2!}h - \frac{u^{(3)}(x)}{3!}h^2 - \frac{u^{(4)}(x)}{4!}h^3 - ... \\
  \pdv{u}{x} &= - \frac{u(x-h) - u(x)}{h} + \frac{u^{(2)}(x)}{2!}h - \frac{u^{(3)}(x)}{3!}h^2 + \frac{u^{(4)}(x)}{4!}h^3 - ...
\end{align}
Subtracting one from the other yields the 3-point stencil approximation for the Laplacian in one dimension denoted $\Delta^{(3)}u(x)$.
\begin{align}
  0 &= \frac{u(x+h) + u(x-h) - 2u(x)}{h} - u^{(2)}(x)h - 2\frac{u^{(4)}(x)}{4!}h^3 + ...\\
  \implies \pdv[order={2}]{u}{x} &=  \underbrace{\frac{u(x-h) -2u(x) + u(x+h)}{h^2}}_{\let\scriptstyle\textstyle
  \substack{=: \Delta^{(3)}u(x)}} + O(h^2)
\end{align}
By combining the 3-point stencils for the $x$ and $y$ directions, we get a two dimensional 5-point stencil.
\begin{align}
  \Delta u(x, y) &= \pdv[order={2}]{u}{x} + \pdv[order={2}]{u}{y}\\
                     &\approx \frac{u(x-h, y) -2u(x, y) + u(x+h, y)}{h^2} + \frac{u(x, y-h) -2u(x, y) + u(x, y+h)}{h^2}\\
                     &= \frac{u(x-h, y)+ u(x+h, y) -4u(x, y) + u(x, y-h) + u(x, y+h)}{h^2}\\
                     &= \frac{1}{h^2} \begin{bmatrix}
                                0 & 1 & 0\\
                                1 & -4 & 1\\
                                0 & 1 & 0
                     \end{bmatrix} u(x, y) = \Delta^{(5)}_h u(x, y) \label{eq:5-point-stencil}
\end{align}
Finally, we obtain a softer discretization by combining two 5-point stencils, shown in \ref{eq:5-point-stencil}, into a 9-point stencil. Consider $\Delta^{(5)}_h u$ with $h = 1$, the side length of a cell in our lattice. Then, the stencil aligns perfectly with our CA. Now consider another stencil rotated by $45^\circ$ with $h=\sqrt{2}$. By combining these two stencils, we get
\begin{equation}
  \begin{bmatrix}
    0 & 1 & 0\\
    1 & -4 & 1\\
    0 & 1 & 0
  \end{bmatrix}
  + \frac{1}{(\sqrt{2})^2}
  \begin{bmatrix}
    1 & 0 & 1\\
    0 & -4 & 0\\
    1 & 0 & 1
  \end{bmatrix}
  = 
  \begin{bmatrix}
    0.5 & 1 & 0.5\\
    1 & -6 & 1\\
    0.5 & 1 & 0.5
  \end{bmatrix}
  = \frac{1}{2}
  \begin{bmatrix}
    0.25 & 0.5 & 0.25\\
    0.5 & -3 & 0.5\\
    0.25 & 0.5 & 0.25
  \end{bmatrix}
  = \frac{1}{2} \Delta^{(9)}_h 
\end{equation}
In this sense, the 9-point stencil approximates the second partial derivative across 8 directions. The positive and negative $x$ and $y$ directions as well as the 4 diagonal directions between them. The constant factor of $\frac{1}{2}$ is consumed by the diffusion constant. We can now convolve $\Delta^{(9)}_h$ over the density matrices of $u$ and $v$ to approximate $\Delta u$ and $\Delta v$ and therefore calculate $\dot{u_n}$ and $\dot{v_n}$ from Def~\ref{def:gs}. We iterate using forward Euler integration as follows
\begin{align}
    u_{n+1} &= u_n + \dot{u}(u_n, v_n)\ \delta t\\
    v_{n+1} &= v_n + \dot{v}(u_n, v_n)\ \delta t
\end{align}
There are a number of constants that affect the behaviour of simulation. These include the diffusion constants, time delta, initial densities, feed rate, and kill rate. We pick a diffusion constant ratio of $D_u = 2D_v$ as this ratio has been shown, in the literature, to elicit complex behaviour\cite{compeau}. The temporal resolution can be adjusted using the time delta $\delta t$. Through spot checks, we find values of $\delta t \in [0.5, 1.0]$ produce interesting behaviour in a reasonable number of epochs (i.e. under 10000). The remaining constants are parameters of the simulation passed in by the calling Chromosome class. As before, we convolve with wrap boundaries to ensure periodic boundary conditions and we cache states during simulation to reduce computation time. When visualising state, we set the colour of a cell based on the ratio of densities of $u$ and $v$ inside it.\\

The simulator allows for two different initialisation settings. Both have a background state populated entirely of reactant ($u=1$, $v = 0$) and apply perturbations of ($u=\frac{1}{2}$, $v = \frac{1}{4}$). The \textit{patch} setting, in the style of Pearson\cite{pearson1993complex}, creates a square perturbation with $\pm1\%$ Gaussian noise as shown in Figure~\ref{fig:patch}. The \textit{splatter} setting produces $n$ perturbation "seeds" of size $3\times3$ as shown in Figure~\ref{fig:splatter}. The patch setting tends to unfold in a reproducible manner as the only source of randomness in the small Gaussian noise. The splatter setting is unpredictable as the final outcome is dependent on the initial seed locations and way in which they collide.
\begin{figure}[!h]
\centering
            \subfloat[$t = 0$]{\includegraphics[width=.3\textwidth]{images/patch/1.png}}\hfill
            \subfloat[$t = 1000$]{\includegraphics[width=.3\textwidth]{images/patch/2.png}}\hfill
            \subfloat[$t = 2000$]{\includegraphics[width=.3\textwidth]{images/patch/3.png}}\hfill
            \subfloat[$t = 3000$]{\includegraphics[width=.3\textwidth]{images/patch/4.png}}\hfill
            \subfloat[$t = 4000$]{\includegraphics[width=.3\textwidth]{images/patch/5.png}}\hfill
            \subfloat[$t = 5000$]{\includegraphics[width=.3\textwidth]{images/patch/6.png}}\hfill
            \caption{Gray-Scott simulation under \textit{patch} initialisation ($f = 0.03$, $k = 0.06$)}
\label{fig:patch}
\end{figure}

\begin{figure}[!h]
\centering
            \subfloat[$t = 0$]{\includegraphics[width=.3\textwidth]{images/splatter/1.png}}\hfill
            \subfloat[$t = 200$]{\includegraphics[width=.3\textwidth]{images/splatter/2.png}}\hfill
            \subfloat[$t = 500$]{\includegraphics[width=.3\textwidth]{images/splatter/3.png}}\hfill
            \subfloat[$t = 1000$]{\includegraphics[width=.3\textwidth]{images/splatter/4.png}}\hfill
            \subfloat[$t = 2000$]{\includegraphics[width=.3\textwidth]{images/splatter/5.png}}\hfill
            \subfloat[$t = 5000$]{\includegraphics[width=.3\textwidth]{images/splatter/6.png}}\hfill
            \caption{Gray-Scott simulation under \textit{splatter} initialisation ($f = 0.03$, $k = 0.06$)}
\label{fig:splatter}
\end{figure}

\section{Genetic Algorithm III} \label{sec:ga-3}

\subsection{Chromosome}
The chromosome is made up of two vectors, \textit{state} and \textit{control}. The state vector contains the parameters of the model, feed and kill rate, as two real numbers, $f$ and $k$. The control vector contains the volatility of these parameters as real numbers $df$ and $dk$. This allows us to implement a variable mutation rate which is important given the search space is made up of a small band of interesting behaviour amidst a background of trivial solutions. The toolkit allows the user to initialise chromosomes in one of two ways. The first choice is to sample a random uniform distribution with $f \in [0.0, 0.30]$ and $k \in [0.0, 0.08]$. The boundaries are based on Munafo's phase diagram in Figure~\ref{fig:xmorphia}. The second choice is to sample pairs close to the saddle-node bifurcation threshold $f = f(4+k)^2$ depicted as the solid line in Figure~\ref{fig:pearsons-threshold}. Values of $f$ are picked uniformly between the roots of the bifurcation parabola, $0.0$ and $0.25$. $k$ is the positive solution of this parabola $k = \frac{1}{2}\sqrt{f} - f$ perturbed by $\pm 10\%$ Gaussian noise and truncated at $k = 0$.

\subsection{Genetic Operators}
The crossover method used is a combination of uniform crossover and blended crossover (BLX-$\alpha$). In uniform crossover, the state of the child $c$ is defined by a value sampled uniformly from the interval between the corresponding state in the parents, $x$ and $y$, as shown below.
\begin{align}\label{eq:uniform-crossover}
  c_f &\sim \mathit{Uniform}(\min(x_f, y_f),\ \max(x_f, y_f))\\
  c_k &\sim \mathit{Uniform}(\min(x_k, y_k),\ \max(x_k, y_k))
\end{align}
However, the control property is different due to the BLX-$\alpha$ algorithm which combines exploration and exploitation. A traditional crossover algorithm seeks to exploit generational knowledge to create novel candidate solutions by deriving a child state interior to the boundaries defined by the parents' states. For example, consider a single-point crossover on a binary string. If both parents have a 1 in the $i^{th}$ position bit, it is impossible for the child to have a 0 in the $i^{th}$ bit. In this sense, BLX-$\alpha$ is not pure crossover as it explores areas of the search outside the parent-defined borders. BLX-$\alpha$ is defined in Def~\ref{def:blx} and visualised in Figure~\ref{fig:blx-alpha}.

\begin{definition}[Blended Crossover (BLX-$\alpha$)]\label{def:blx}
We define the blended crossover of real numbers $x_i$, $y_i \in [a_i, b_i]$ with $x_i < y_i$ and parameter $\alpha \in \mathbb{R^+}$ as a sample\\
\begin{equation}
  BLX(x_i, y_i, \alpha) \sim \mathit{Uniform}(x_i - \alpha(y_i - x_i),\  y_i + \alpha(y_i - x_i))
\end{equation}
\end{definition}
The hyperparameter $\alpha$ defines how much exploration the operator undertakes as a fraction of the difference between the parent states. In the special case $\alpha = 0$ this is uniform crossover. When $\alpha$ is maximised, this approaches a uniform mutation operator where the value of a child gene is a uniform sample across the predefined gene boundaries $a_i$ and $b_i$.\\

\begin{figure}[!h]
\centering
    \includegraphics[width=.5\textwidth]{images/blx.png}
    \caption{Blended Crossover \cite{abido2006multiobjective}}
\label{fig:blx-alpha}
\end{figure}

To ensure exploration is occurring for state properties too, a Gaussian mutation is added to $f$ and $k$. The variance of this mutation is dictated by the control property.

\subsection{Fitness Function}
As before, we simulate a true CA based on the goal parameters and maintain a surrogate CA which is regularly synchronised with the true CA. The loss for a single cell is calculated by finding the difference in density between the true and surrogate cell as a fraction of the true density. The loss of the whole CA is the mean of these values and the fitness is defined as $1 - \textnormal{loss}$. This is a continuous extension of the XOR loss used for life-like CA.\\

\section{Evolutionary Strategy} \label{sec:es}
Evolutionary strategies (ES) are black-box optimization algorithms suited to continuous domains. Some ES use fitness-based recombination where parents with a higher fitness produce more offspring\cite{hansen2015evolution}. In this case, selection pressure and exploitation of generational knowledge are pursued simultaneously, so traditional environmental selection can be omitted. For our use case, we stick with a fitness-independent recombination method and a separate environmental selection scheme to allow flexibility in tuning both processes individually.\\

An ES individual has the form $a_i: (\bm{x}, \bm{\sigma}, F(\bm{x}))$ which are the state parameters, control parameters, and fitness respectively. The control parameters control the average size of mutation and are specific to each individual. ES also often use more than 2 parents for recombination unlike GA. Typically, all children are produced from the top $\rho$ parents with $\rho \leq \mu$. These are called the mixing parents. Common recombination operators include:
\begin{itemize}
  \item Discrete: Each of the offspring's state variables is inherited from one of the $\rho$ parents.
  \item Intermediate: The offspring's state is the mean of the states of the parents.
  \item Weighted Intermediate: The offspring's state is a weighted combination of the parent states with a weighting function that increases monotonically with fitness.
\end{itemize}

A fundamental idea in ES is parameter control by self-adaptation. For a self-adapting ES, control parameters are evolved just like state parameters. Each of the $\lambda$ offspring are generated as follows
\begin{equation}
b_i \gets
\begin{cases}
    \bm{x}_i = \bar{\bm{x}} + \bm{\sigma}_i\bm{N_i(0, I)},\\
    \bm{\sigma_i} = \bar{\bm{\sigma}}e^{\tau\bm{N_i(0, I)}},\\
    F_i = F(\bm{x}_i)
\end{cases}
\end{equation}
Where we define the intermediate recombination operator as the arithmetic mean
\begin{equation}
  \bar{\bm{y}} = \frac{1}{\rho}\sum_{m=1}^{\rho}{\bm{y}_m}
\end{equation}
where $\bm{y}_m$ is the $\bm{y}$ property of the $m^{th}$ best mixing parent by fitness. The state vectors receive Gaussian mutation with variance defined by the control parameters and the control parameters receive log-normal mutation with variance dependent on a constant learning rate $\tau$. This is usually set proportional to $\frac{1}{\sqrt{n}}$ but can be tuned as a hyperparameter. The terms $\bm{N_i(0, I)}$ are normally distributed vectors with the same dimensions as the vector being mutated.\\

We implement this strategy but, in the style of Hansen et al.\cite{hansen2015evolution}, we apply mutation in two parts. There is a common mutation applied to all control parameter components of $e^{\tau_1{N_i(0, 1)}}$ and a specific mutation applied to each component individually of $e^{\tau_2\bm{N_i(0, I)}}$ with $\tau_1 = n^{-\frac{1}{2}}$ and $\tau_1 = n^{-\frac{1}{4}}$.\\

% \begin{figure}[!h]
% \centering  
%             \hfill
%             \subfloat[Isotropic Mutation]{\includegraphics[width=.2\textwidth]{images/es-iso-mutation.png}}\hfill
%             \subfloat[Axis Parallel Mutation]{\includegraphics[width=.2\textwidth]{images/es-axis-parallel-mutation.png}}\hfill
%             \subfloat[General Mutation]{\includegraphics[width=.2\textwidth]{images/es-general-mutation.png}}\hfill\hfill
%             \caption{}
% \label{fig:es-mutations}
% \end{figure}

% However, the self-adapting ES uses isotropic mutations or axis parallel mutations which means it is difficult to choose appropriately sized mutations for correlated state variables. To address this, we use a covariance matrix adaptation evolutionary strategy (CMA-ES) which is the state-of-the-art in continuous domain evolutionary strategies. \\

% TODO?

